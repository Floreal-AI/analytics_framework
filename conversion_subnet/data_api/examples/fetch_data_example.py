#!/usr/bin/env python3
"""
Standalone example: Fetch training and test data from VoiceForm API.

This example demonstrates:
- How to fetch training data
- How to fetch test data  
- Data structure inspection
- Basic data analysis
- CSV saving functionality
- Data compatibility checking

Setup:
1. Copy template: cp conversion_subnet/data_api/env.example conversion_subnet/data_api/.env
2. Edit .env with your API credentials
3. Run with: python -m conversion_subnet.data_api.examples.fetch_data_example
"""

import asyncio
import numpy as np
from pathlib import Path

from conversion_subnet.data_api.core import (
    VoiceFormAPIClient,
    VoiceFormAPIConfig,
    APIError,
    DataValidationError
)


async def main():
    """
    Fetch training and test data and perform detailed analysis.
    """
    
    print("ğŸš€ VoiceForm Data API - Fetch Training & Test Data")
    print("=" * 60)
    print("This example fetches both datasets and shows their structure\n")
    
    # Load configuration from .env file
    env_path = Path(__file__).parent.parent.parent.parent / ".env"
    print(f"ğŸ“‚ Loading configuration from: {env_path}")
    
    try:
        # Load configuration from .env file
        config = VoiceFormAPIConfig.from_env(str(env_path))
        client = VoiceFormAPIClient(config)
        print("âœ… Configuration loaded successfully")
    except Exception as e:
        print(f"âŒ Failed to load configuration: {e}")
        print("ğŸ’¡ Make sure you have a .env file with:")
        print("   VOICEFORM_API_KEY=your-api-key")
        print("   VOICEFORM_API_BASE_URL=your-api-url")
        print("   Copy from: cp conversion_subnet/data_api/env.example conversion_subnet/data_api/.env")
        return
    
    try:
        # Step 1: Fetch Training Data
        print("\n" + "="*60)
        print("ğŸ¯ STEP 1: FETCHING TRAINING DATA")
        print("="*60)
        
        print("ğŸ”„ Requesting training data...")
        training_data = await client.fetch_training_data(
            limit=100,          # Get 100 samples
            offset=0,           # Start from beginning  
            round_number=1,     # Training round 1
            save=True          # Save as CSV (default: True)
        )
        
        print("âœ… Training data fetched successfully!")
        print(f"\nğŸ“Š TRAINING DATA SUMMARY:")
        print(f"   ğŸ“ Dataset shape: {training_data.features.shape} (samples Ã— features)")
        print(f"   ğŸ·ï¸  Target shape: {training_data.targets.shape}")
        print(f"   ğŸ“‹ Feature count: {len(training_data.feature_names)}")
        print(f"   ğŸ”„ Training round: {training_data.round_number}")
        print(f"   ğŸ• Last updated: {training_data.updated_at}")
        print(f"   ğŸ’¾ Saved to: data/train_data.csv")
        
        # Feature names
        print(f"\nğŸ“ FEATURE NAMES:")
        if len(training_data.feature_names) <= 10:
            print(f"   All features: {training_data.feature_names}")
        else:
            print(f"   First 10: {training_data.feature_names[:10]}")
            print(f"   ... and {len(training_data.feature_names) - 10} more")
        
        # Training data statistics
        print(f"\nğŸ“ˆ TRAINING STATISTICS:")
        print(f"   Features:")
        print(f"     â€¢ Min value: {training_data.features.min():.3f}")
        print(f"     â€¢ Max value: {training_data.features.max():.3f}")
        print(f"     â€¢ Mean: {training_data.features.mean():.3f}")
        print(f"     â€¢ Std dev: {training_data.features.std():.3f}")
        
        print(f"   Targets:")
        unique_targets, target_counts = np.unique(training_data.targets, return_counts=True)
        print(f"     â€¢ Unique values: {unique_targets}")
        print(f"     â€¢ Distribution: {dict(zip(unique_targets, target_counts))}")
        print(f"     â€¢ Class balance: {target_counts.min()}/{target_counts.max()} (min/max)")
        
        # Step 2: Fetch Test Data
        print("\n" + "="*60)
        print("ğŸ¯ STEP 2: FETCHING TEST DATA")
        print("="*60)
        
        print("ğŸ”„ Requesting test data...")
        test_data = await client.fetch_test_data(
            limit=100,          # Get 100 samples
            offset=0,           # Start from beginning
            save=True          # Save as CSV (default: False for test data)
        )
        
        print("âœ… Test data fetched successfully!")
        print(f"\nğŸ“Š TEST DATA SUMMARY:")
        print(f"   ğŸ“ Dataset shape: {test_data.features.shape} (samples Ã— features)")
        print(f"   ğŸ“‹ Feature count: {len(test_data.feature_names)}")
        print(f"   â° Submission deadline: {test_data.submission_deadline}")
        print(f"   ğŸ’¾ Saved to: data/test_data.csv")
        
        # Test data statistics
        print(f"\nğŸ“ˆ TEST STATISTICS:")
        print(f"   Features:")
        print(f"     â€¢ Min value: {test_data.features.min():.3f}")
        print(f"     â€¢ Max value: {test_data.features.max():.3f}")
        print(f"     â€¢ Mean: {test_data.features.mean():.3f}")
        print(f"     â€¢ Std dev: {test_data.features.std():.3f}")
        
        # Step 3: Dataset Comparison
        print("\n" + "="*60)
        print("ğŸ¯ STEP 3: DATASET COMPATIBILITY CHECK")
        print("="*60)
        
        # Feature compatibility
        features_match = training_data.feature_names == test_data.feature_names
        if features_match:
            print("âœ… FEATURE COMPATIBILITY: PERFECT MATCH")
            print(f"   ğŸ“Š Both datasets have {len(training_data.feature_names)} identical features")
        else:
            print("âŒ FEATURE COMPATIBILITY: MISMATCH DETECTED")
            print(f"   Training features: {len(training_data.feature_names)}")
            print(f"   Test features: {len(test_data.feature_names)}")
            
            # Find differences
            train_set = set(training_data.feature_names)
            test_set = set(test_data.feature_names)
            missing_in_test = train_set - test_set
            missing_in_train = test_set - train_set
            
            if missing_in_test:
                print(f"   Missing in test: {list(missing_in_test)[:5]}...")
            if missing_in_train:
                print(f"   Missing in train: {list(missing_in_train)[:5]}...")
        
        # Feature range comparison
        print(f"\nğŸ“Š FEATURE RANGE COMPARISON:")
        train_min, train_max = training_data.features.min(), training_data.features.max()
        test_min, test_max = test_data.features.min(), test_data.features.max()
        
        print(f"   Training data ranges: [{train_min:.3f}, {train_max:.3f}]")
        print(f"   Test data ranges:     [{test_min:.3f}, {test_max:.3f}]")
        
        # Check for distribution shift
        train_mean = training_data.features.mean()
        test_mean = test_data.features.mean()
        mean_diff = abs(train_mean - test_mean)
        
        if mean_diff < 0.1:
            print(f"âœ… Distribution similarity: Good (mean diff: {mean_diff:.3f})")
        elif mean_diff < 0.5:
            print(f"âš ï¸  Distribution similarity: Moderate (mean diff: {mean_diff:.3f})")
        else:
            print(f"âŒ Distribution similarity: Poor (mean diff: {mean_diff:.3f})")
        
        # Step 4: Ready for ML
        print("\n" + "="*60)
        print("ğŸ¯ STEP 4: MACHINE LEARNING READINESS")
        print("="*60)
        
        print("âœ… DATASETS ARE READY FOR ML WORKFLOWS!")
        print(f"\nğŸ¯ TRAINING SETUP:")
        print(f"   â€¢ Samples: {training_data.features.shape[0]:,}")
        print(f"   â€¢ Features: {training_data.features.shape[1]:,}")
        print(f"   â€¢ Target classes: {len(np.unique(training_data.targets))}")
        print(f"   â€¢ Data file: data/train_data.csv")
        
        print(f"\nğŸ§ª PREDICTION SETUP:")
        print(f"   â€¢ Test samples: {test_data.features.shape[0]:,}")
        print(f"   â€¢ Features: {test_data.features.shape[1]:,}")
        print(f"   â€¢ Submission deadline: {test_data.submission_deadline}")
        print(f"   â€¢ Data file: data/test_data.csv")
        
        print(f"\nğŸ’¡ NEXT STEPS:")
        print(f"   1. ğŸ“ Load data: pd.read_csv('data/train_data.csv')")
        print(f"   2. ğŸ¯ Train model: X = features, y = target column")
        print(f"   3. ğŸ§ª Predict: model.predict(test_features)")
        print(f"   4. ğŸ“¤ Submit before: {test_data.submission_deadline}")
        
        print(f"\nğŸ“‹ SAMPLE CODE:")
        print(f"   ```python")
        print(f"   import pandas as pd")
        print(f"   from sklearn.ensemble import RandomForestClassifier")
        print(f"   ")
        print(f"   # Load data")
        print(f"   train_df = pd.read_csv('data/train_data.csv')")
        print(f"   test_df = pd.read_csv('data/test_data.csv')")
        print(f"   ")
        print(f"   # Prepare training data")
        print(f"   X_train = train_df.drop('target', axis=1)")
        print(f"   y_train = train_df['target']")
        print(f"   X_test = test_df")
        print(f"   ")
        print(f"   # Train and predict")
        print(f"   model = RandomForestClassifier()")
        print(f"   model.fit(X_train, y_train)")
        print(f"   predictions = model.predict(X_test)")
        print(f"   ```")
        
    except APIError as e:
        print(f"\nâŒ API ERROR: {e}")
        if hasattr(e, 'status_code'):
            print(f"   HTTP Status: {e.status_code}")
        print("   This could be due to:")
        print("   â€¢ Invalid API credentials")
        print("   â€¢ Network connectivity issues")
        print("   â€¢ API service temporarily unavailable")
        
    except DataValidationError as e:
        print(f"\nâŒ DATA VALIDATION ERROR: {e}")
        print("   This could be due to:")
        print("   â€¢ Unexpected API response format")
        print("   â€¢ Missing required fields")
        print("   â€¢ Data corruption during transfer")
        
    except Exception as e:
        print(f"\nâŒ UNEXPECTED ERROR: {e}")
        print("   Please check your setup and try again")
        
    finally:
        await client.close()
        print(f"\nğŸ”’ Client connection closed")
        print("=" * 60)
        print("âœ… Example completed!")


if __name__ == '__main__':
    asyncio.run(main()) 