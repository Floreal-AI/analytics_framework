{
  "exitstatus": 1,
  "test_counts": {
    "total": 52,
    "passed": 35,
    "failed": 8,
    "skipped": 0,
    "errors": 9
  },
  "duration": 1.6738708019256592,
  "failed_tests": [
    {
      "name": "tests/unit/miner/test_miner.py::TestBinaryClassificationMiner::test_init",
      "duration": 0.00017870799638330936,
      "error_message": "self = <test_miner.TestBinaryClassificationMiner object at 0x13617a140>\ntest_config = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[64, 32, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\n\n    def test_init(self, test_config):\n        \"\"\"Test that the miner initializes correctly.\"\"\"\n>       miner = BinaryClassificationMiner(test_config)\n\ntests/unit/miner/test_miner.py:18: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/miner.py:18: in __init__\n    self.device = torch.device(config.neuron.device)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[64, 32, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\nitem = 'neuron'\n\n    def __getattr__(self, item: str) -> Any:\n        private_attributes = object.__getattribute__(self, '__private_attributes__')\n        if item in private_attributes:\n            attribute = private_attributes[item]\n            if hasattr(attribute, '__get__'):\n                return attribute.__get__(self, type(self))  # type: ignore\n    \n            try:\n                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                return self.__pydantic_private__[item]  # type: ignore\n            except KeyError as exc:\n                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n        else:\n            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n            # See `BaseModel.__repr_args__` for more details\n            try:\n                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n            except AttributeError:\n                pydantic_extra = None\n    \n            if pydantic_extra:\n                try:\n                    return pydantic_extra[item]\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                if hasattr(self.__class__, item):\n                    return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                else:\n                    # this is the current error\n>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE                   AttributeError: 'ConversionSubnetConfig' object has no attribute 'neuron'\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:989: AttributeError"
    },
    {
      "name": "tests/unit/miner/test_miner.py::TestBinaryClassificationMiner::test_model_architecture",
      "duration": 0.0001723750028759241,
      "error_message": "self = <test_miner.TestBinaryClassificationMiner object at 0x13617b0a0>\ntest_config = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[32, 16, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\n\n    def test_model_architecture(self, test_config):\n        \"\"\"Test that the model architecture matches the configuration.\"\"\"\n        # Set custom layer sizes\n        test_config.miner.hidden_sizes = [32, 16, 1]\n    \n>       miner = BinaryClassificationMiner(test_config)\n\ntests/unit/miner/test_miner.py:33: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/miner.py:18: in __init__\n    self.device = torch.device(config.neuron.device)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[32, 16, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\nitem = 'neuron'\n\n    def __getattr__(self, item: str) -> Any:\n        private_attributes = object.__getattribute__(self, '__private_attributes__')\n        if item in private_attributes:\n            attribute = private_attributes[item]\n            if hasattr(attribute, '__get__'):\n                return attribute.__get__(self, type(self))  # type: ignore\n    \n            try:\n                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                return self.__pydantic_private__[item]  # type: ignore\n            except KeyError as exc:\n                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n        else:\n            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n            # See `BaseModel.__repr_args__` for more details\n            try:\n                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n            except AttributeError:\n                pydantic_extra = None\n    \n            if pydantic_extra:\n                try:\n                    return pydantic_extra[item]\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                if hasattr(self.__class__, item):\n                    return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                else:\n                    # this is the current error\n>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE                   AttributeError: 'ConversionSubnetConfig' object has no attribute 'neuron'\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:989: AttributeError"
    },
    {
      "name": "tests/unit/miner/test_miner.py::TestBinaryClassificationMiner::test_model_device",
      "duration": 0.00031799999851500615,
      "error_message": "self = <test_miner.TestBinaryClassificationMiner object at 0x13617a440>\ntest_config = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[64, 32, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\n\n    def test_model_device(self, test_config):\n        \"\"\"Test that the model is on the correct device.\"\"\"\n        test_config.miner.device = \"cpu\"\n>       miner = BinaryClassificationMiner(test_config)\n\ntests/unit/miner/test_miner.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/miner.py:18: in __init__\n    self.device = torch.device(config.neuron.device)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[64, 32, 1], learning_rate=0.001, b...console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml'))\nitem = 'neuron'\n\n    def __getattr__(self, item: str) -> Any:\n        private_attributes = object.__getattribute__(self, '__private_attributes__')\n        if item in private_attributes:\n            attribute = private_attributes[item]\n            if hasattr(attribute, '__get__'):\n                return attribute.__get__(self, type(self))  # type: ignore\n    \n            try:\n                # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                return self.__pydantic_private__[item]  # type: ignore\n            except KeyError as exc:\n                raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n        else:\n            # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n            # See `BaseModel.__repr_args__` for more details\n            try:\n                pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n            except AttributeError:\n                pydantic_extra = None\n    \n            if pydantic_extra:\n                try:\n                    return pydantic_extra[item]\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                if hasattr(self.__class__, item):\n                    return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                else:\n                    # this is the current error\n>                   raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\nE                   AttributeError: 'ConversionSubnetConfig' object has no attribute 'neuron'\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:989: AttributeError"
    },
    {
      "name": "tests/unit/utils/test_configuration.py::TestConfiguration::test_load_config_from_env",
      "duration": 0.0038229580022743903,
      "error_message": "self = <test_configuration.TestConfiguration object at 0x13617b190>\n\n    @patch.dict(os.environ, {\"CONVERSION_NETUID\": \"4\", \"CONVERSION_MINER__DEVICE\": \"cuda\"})\n    def test_load_config_from_env(self):\n        \"\"\"Test loading config from environment variables.\"\"\"\n        # Load config (should use env vars)\n        config = load_config()\n    \n        # Check that values were loaded from env vars\n>       assert config.netuid == 4\nE       AssertionError: assert 1 == 4\nE        +  where 1 = ConversionSubnetConfig(miner=MinerConfig(device='cpu', input_size=40, hidden_sizes=[64, 32, 1], learning_rate=0.001, batch_size=32, epochs=10, checkpoint_dir=PosixPath('/Users/admin/.bittensor/checkpoints'), timeout=60), validator=ValidatorConfig(sample_size=10, ema_beta=0.1, dataset_path=None, timeout=60, epoch_length=100, num_concurrent_forwards=1), logging=LoggingConfig(level='INFO', log_dir=None, json_logging=True, console_logging=True), netuid=1, subtensor_chain='finney', config_path=PosixPath('/Users/admin/.bittensor/config.yml')).netuid\n\ntests/unit/utils/test_configuration.py:118: AssertionError"
    },
    {
      "name": "tests/unit/utils/test_configuration.py::TestConfiguration::test_load_config_priority",
      "duration": 0.002009832998737693,
      "error_message": "self = <test_configuration.TestConfiguration object at 0x136178e80>\ntmp_path = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-1/test_load_config_priority0')\n\n    def test_load_config_priority(self, tmp_path):\n        \"\"\"Test config loading priority (env vars > YAML > defaults).\"\"\"\n        # Create a test config file\n        config_data = {\n            \"netuid\": 3,\n            \"miner\": {\n                \"device\": \"cuda\",\n                \"input_size\": 50\n            }\n        }\n    \n        config_path = tmp_path / \"test_config.yml\"\n        with open(config_path, 'w') as f:\n            yaml.dump(config_data, f)\n    \n        # Set environment variables\n        with patch.dict(os.environ, {\"CONVERSION_NETUID\": \"4\"}):\n            # Load config\n            config = load_config(config_path)\n    \n            # Env vars should take precedence over YAML\n>           assert config.netuid == 4\nE           AssertionError: assert 3 == 4\nE            +  where 3 = ConversionSubnetConfig(miner=MinerConfig(device='cuda', input_size=50, hidden_sizes=[64, 32, 1], learning_rate=0.001, batch_size=32, epochs=10, checkpoint_dir=PosixPath('/Users/admin/.bittensor/checkpoints'), timeout=60), validator=ValidatorConfig(sample_size=10, ema_beta=0.1, dataset_path=None, timeout=60, epoch_length=100, num_concurrent_forwards=1), logging=LoggingConfig(level='INFO', log_dir=None, json_logging=True, console_logging=True), netuid=3, subtensor_chain='finney', config_path=PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-1/test_load_config_priority0/test_config.yml')).netuid\n\ntests/unit/utils/test_configuration.py:145: AssertionError"
    },
    {
      "name": "tests/unit/validator/test_forward.py::TestForward::test_forward",
      "duration": 0.0006027499985066243,
      "error_message": "self = <Coroutine test_forward>\n\n    def runtest(self) -> None:\n        self.obj = wrap_in_sync(\n            # https://github.com/pytest-dev/pytest-asyncio/issues/596\n            self.obj,  # type: ignore[has-type]\n        )\n>       super().runtest()\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:1069: in inner\n    _loop.run_until_complete(task)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/asyncio/base_events.py:649: in run_until_complete\n    return future.result()\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1393: in patched\n    with self.decoration_helper(patched,\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:135: in __enter__\n    return next(self.gen)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1358: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:492: in enter_context\n    result = _cm_type.__enter__(cm)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1447: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x1362ba230>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <function forward at 0x133d848b0> does not have the attribute 'validate_features'\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1420: AttributeError"
    },
    {
      "name": "tests/unit/validator/test_reward.py::TestValidator::test_diversity_reward",
      "duration": 0.0002548749980633147,
      "error_message": "self = <test_reward.TestValidator object at 0x1364397e0>\n\n    def test_diversity_reward(self):\n        \"\"\"Test diversity reward calculation.\"\"\"\n        validator = Validator()\n    \n        # Conservative prediction (0.5) should have 0 diversity reward\n>       assert validator.diversity_reward(0.5) == 0.0\nE       assert 1.0 == 0.0\nE        +  where 1.0 = diversity_reward(0.5)\nE        +    where diversity_reward = <conversion_subnet.validator.reward.Validator object at 0x137b1afb0>.diversity_reward\n\ntests/unit/validator/test_reward.py:107: AssertionError"
    },
    {
      "name": "tests/unit/validator/test_reward.py::TestValidator::test_reward_full_flow",
      "duration": 0.0011672500040731393,
      "error_message": "self = <test_reward.TestValidator object at 0x13643be50>\nmock_log_metrics = <MagicMock name='log_metrics' id='5226443392'>\n\n    @patch('conversion_subnet.validator.utils.log_metrics')\n    def test_reward_full_flow(self, mock_log_metrics):\n        \"\"\"Test the full reward flow for a miner's response.\"\"\"\n        validator = Validator()\n    \n        # Create a sample response\n        response = MagicMock(spec=ConversionSynapse)\n        response.prediction = {'conversion_happened': 1, 'time_to_conversion_seconds': 70.0}\n        response.confidence = 0.8\n        response.response_time = 15.0\n        response.miner_uid = 42\n    \n        # Create sample ground truth\n        true = {'conversion_happened': 1, 'time_to_conversion_seconds': 65.0}\n    \n        # Calculate reward\n        reward = validator.reward(true, response)\n    \n        # Check that reward is calculated correctly\n        assert 0.0 <= reward <= 1.0\n    \n        # Check that EMA is updated\n        assert 42 in validator.ema_scores\n    \n        # Check that ground truth is stored\n        assert true in validator.ground_truth_history\n    \n        # Check that log_metrics is called\n>       mock_log_metrics.assert_called_once_with(response, reward, true)\n\ntests/unit/validator/test_reward.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <MagicMock name='log_metrics' id='5226443392'>\nargs = (<MagicMock spec='ConversionSynapse' id='5226436144'>, 0.5576666666666666, {'conversion_happened': 1, 'time_to_conversion_seconds': 65.0})\nkwargs = {}, msg = \"Expected 'log_metrics' to be called once. Called 0 times.\"\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n>           raise AssertionError(msg)\nE           AssertionError: Expected 'log_metrics' to be called once. Called 0 times.\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:940: AssertionError"
    }
  ]
}