{
  "exitstatus": 1,
  "test_counts": {
    "total": 52,
    "passed": 16,
    "failed": 1,
    "skipped": 0,
    "errors": 0
  },
  "duration": 0.8382949829101562,
  "failed_tests": [
    {
      "name": "tests/unit/miner/test_train.py::TestModelTraining::test_load_model",
      "duration": 0.0029850420032744296,
      "error_message": "self = <test_train.TestModelTraining object at 0x132efe920>\ntmp_checkpoint_dir = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-6/test_load_model0/checkpoints')\n\n    def test_load_model(self, tmp_checkpoint_dir):\n        \"\"\"Test load_model function.\"\"\"\n        # Create mock miner with mock model\n        mock_miner = MagicMock()\n        mock_model = MagicMock()\n        mock_miner.model = mock_model\n    \n        # Mock state_dict to return a dictionary\n        mock_model.state_dict.return_value = {\"layer1.weight\": torch.randn(5, 5)}\n    \n        # Save a model first\n        save_model(mock_miner, tmp_checkpoint_dir, \"test_model.pt\")\n    \n        # Call load_model\n>       load_model(mock_miner, tmp_checkpoint_dir / \"test_model.pt\")\n\ntests/unit/miner/test_train.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/train.py:253: in load_model\n    miner.model.load_state_dict(torch.load(checkpoint_path, map_location=miner.device))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:1516: in load\n    return _load(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2114: in _load\n    result = unpickler.load()\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:532: in load\n    self.append(self.persistent_load(pid))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2078: in persistent_load\n    typed_storage = load_tensor(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2049: in load_tensor\n    typed_storage = torch.storage.TypedStorage(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[AttributeError(\"'torch.storage.TypedStorage' object has no attribute '_untyped_storage'\") raised in repr()] TypedStorage object at 0x133058f70>\ndevice = None, dtype = torch.float32, wrap_storage = <MagicMock name='mock.device()' id='5150912672'>\n_internal = True\n\n    def __init__(\n        self,\n        *args,\n        device=None,\n        dtype=None,\n        wrap_storage=None,\n        _internal=False,\n    ):\n        if not _internal:\n            _warn_typed_storage_removal()\n        arg_error_msg = (\n            \"TypedStorage.__init__ received an invalid combination \"\n            \"of arguments. Expected one of:\\n\"\n            \" * (*, torch.device device, torch.dtype dtype)\\n\"\n            \" * (int size, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (Sequence data, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (*, UntypedStorage wrap_storage, torch.dtype dtype)\"\n        )\n    \n        if wrap_storage is not None:\n            if len(args) != 0:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nNo positional arguments should be given when using \"\n                    \"'wrap_storage'\"\n                )\n    \n            if dtype is None:\n                raise RuntimeError(\n                    arg_error_msg + \"\\nArgument 'dtype' must be specified\"\n                )\n    \n            if not isinstance(dtype, torch.dtype):\n                raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'dtype' must be torch.dtype, not {type(dtype)}\"\n                )\n    \n            if device is not None:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nArgument 'device' should not be specified when 'wrap_storage' is given\"\n                )\n    \n            self.dtype = dtype\n    \n            if not isinstance(wrap_storage, torch.UntypedStorage):\n>               raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'wrap_storage' must be UntypedStorage, but got {type(wrap_storage)}\"\n                )\nE               TypeError: TypedStorage.__init__ received an invalid combination of arguments. Expected one of:\nE                * (*, torch.device device, torch.dtype dtype)\nE                * (int size, *, torch.device device, torch.dtype dtype)\nE                * (Sequence data, *, torch.device device, torch.dtype dtype)\nE                * (*, UntypedStorage wrap_storage, torch.dtype dtype)\nE               Argument 'wrap_storage' must be UntypedStorage, but got <class 'unittest.mock.MagicMock'>\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/storage.py:827: TypeError"
    }
  ]
}