{
  "logs": [
    {
      "timestamp": "2025-05-03T16:00:27.073807",
      "level": "INFO",
      "message": "Starting test session",
      "metadata": {
        "test_dir": "/Users/admin/Documents/PersonalProjects/bittensor/analytics_framework/test-results"
      }
    },
    {
      "timestamp": "2025-05-03T16:00:27.078254",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.094872",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.101522",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.107169",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.111258",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.115610",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.120401",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.126046",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.128341",
      "level": "ERROR",
      "message": "Error in forward: mat1 and mat2 shapes cannot be multiplied (1x0 and 40x16)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.132696",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.207958",
      "level": "INFO",
      "message": "Epoch 1/1 - train_loss: 0.5000, train_acc: 0.2500, val_loss: 0.5000, val_acc: 0.2500",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.215047",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-6/test_save_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.217470",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-6/test_load_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.396719",
      "level": "INFO",
      "message": "Test session completed",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T16:00:27.850530",
      "level": "INFO",
      "message": "Test session finished with exit status 1",
      "metadata": {
        "exitstatus": 1,
        "test_counts": {
          "total": 52,
          "passed": 16,
          "failed": 1,
          "skipped": 0,
          "errors": 0
        },
        "duration": 0.8382949829101562,
        "failed_tests": [
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_load_model",
            "duration": 0.0029850420032744296,
            "error_message": "self = <test_train.TestModelTraining object at 0x132efe920>\ntmp_checkpoint_dir = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-6/test_load_model0/checkpoints')\n\n    def test_load_model(self, tmp_checkpoint_dir):\n        \"\"\"Test load_model function.\"\"\"\n        # Create mock miner with mock model\n        mock_miner = MagicMock()\n        mock_model = MagicMock()\n        mock_miner.model = mock_model\n    \n        # Mock state_dict to return a dictionary\n        mock_model.state_dict.return_value = {\"layer1.weight\": torch.randn(5, 5)}\n    \n        # Save a model first\n        save_model(mock_miner, tmp_checkpoint_dir, \"test_model.pt\")\n    \n        # Call load_model\n>       load_model(mock_miner, tmp_checkpoint_dir / \"test_model.pt\")\n\ntests/unit/miner/test_train.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/train.py:253: in load_model\n    miner.model.load_state_dict(torch.load(checkpoint_path, map_location=miner.device))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:1516: in load\n    return _load(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2114: in _load\n    result = unpickler.load()\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:532: in load\n    self.append(self.persistent_load(pid))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2078: in persistent_load\n    typed_storage = load_tensor(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2049: in load_tensor\n    typed_storage = torch.storage.TypedStorage(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[AttributeError(\"'torch.storage.TypedStorage' object has no attribute '_untyped_storage'\") raised in repr()] TypedStorage object at 0x133058f70>\ndevice = None, dtype = torch.float32, wrap_storage = <MagicMock name='mock.device()' id='5150912672'>\n_internal = True\n\n    def __init__(\n        self,\n        *args,\n        device=None,\n        dtype=None,\n        wrap_storage=None,\n        _internal=False,\n    ):\n        if not _internal:\n            _warn_typed_storage_removal()\n        arg_error_msg = (\n            \"TypedStorage.__init__ received an invalid combination \"\n            \"of arguments. Expected one of:\\n\"\n            \" * (*, torch.device device, torch.dtype dtype)\\n\"\n            \" * (int size, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (Sequence data, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (*, UntypedStorage wrap_storage, torch.dtype dtype)\"\n        )\n    \n        if wrap_storage is not None:\n            if len(args) != 0:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nNo positional arguments should be given when using \"\n                    \"'wrap_storage'\"\n                )\n    \n            if dtype is None:\n                raise RuntimeError(\n                    arg_error_msg + \"\\nArgument 'dtype' must be specified\"\n                )\n    \n            if not isinstance(dtype, torch.dtype):\n                raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'dtype' must be torch.dtype, not {type(dtype)}\"\n                )\n    \n            if device is not None:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nArgument 'device' should not be specified when 'wrap_storage' is given\"\n                )\n    \n            self.dtype = dtype\n    \n            if not isinstance(wrap_storage, torch.UntypedStorage):\n>               raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'wrap_storage' must be UntypedStorage, but got {type(wrap_storage)}\"\n                )\nE               TypeError: TypedStorage.__init__ received an invalid combination of arguments. Expected one of:\nE                * (*, torch.device device, torch.dtype dtype)\nE                * (int size, *, torch.device device, torch.dtype dtype)\nE                * (Sequence data, *, torch.device device, torch.dtype dtype)\nE                * (*, UntypedStorage wrap_storage, torch.dtype dtype)\nE               Argument 'wrap_storage' must be UntypedStorage, but got <class 'unittest.mock.MagicMock'>\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/storage.py:827: TypeError"
          }
        ]
      }
    }
  ],
  "metadata": {
    "generated_at": "2025-05-03T16:00:27.886798",
    "log_count": 16
  }
}