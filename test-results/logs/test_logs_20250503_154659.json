{
  "logs": [
    {
      "timestamp": "2025-05-03T15:46:58.263336",
      "level": "INFO",
      "message": "Starting test session",
      "metadata": {
        "test_dir": "/Users/admin/Documents/PersonalProjects/bittensor/analytics_framework/test-results"
      }
    },
    {
      "timestamp": "2025-05-03T15:46:58.275093",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.404065",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.453422",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.529567",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.535128",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.539689",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.544363",
      "level": "ERROR",
      "message": "Error in forward: too many dimensions 'str'",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.552584",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.553894",
      "level": "ERROR",
      "message": "Error in forward: too many dimensions 'str'",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.561615",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.562878",
      "level": "ERROR",
      "message": "Error in forward: too many dimensions 'str'",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.567657",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.611436",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.648511",
      "level": "INFO",
      "message": "Epoch 1/1 - train_loss: 0.8496, train_acc: 0.0000, val_loss: 0.8496, val_acc: 0.0000",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.661420",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.666211",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-2/test_save_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.676746",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.678435",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-2/test_load_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.680784",
      "level": "INFO",
      "message": "Loaded model checkpoint from /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-2/test_load_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.708938",
      "level": "ERROR",
      "message": "Missing required features: ['session_id']",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.710448",
      "level": "ERROR",
      "message": "Feature type validation errors: ['has_target_entity must be 0 or 1, got not_an_int']",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:58.712567",
      "level": "WARNING",
      "message": "Feature hour_of_day could not be converted to float",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:59.012362",
      "level": "INFO",
      "message": "Test session completed",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:46:59.440884",
      "level": "INFO",
      "message": "Test session finished with exit status 1",
      "metadata": {
        "exitstatus": 1,
        "test_counts": {
          "total": 52,
          "passed": 41,
          "failed": 11,
          "skipped": 0,
          "errors": 0
        },
        "duration": 1.3612258434295654,
        "failed_tests": [
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_miner_response_to_validator",
            "duration": 0.0020032079992233776,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x1291c5900>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x12930b610>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_miner_response_to_validator(self, mock_miner, sample_features):\n        \"\"\"Test that miner can process features and return valid response.\"\"\"\n        # Create a sample synapse with features\n        synapse = ConversionSynapse(features=sample_features)\n    \n        # Add required dendrite property for blacklist\n>       synapse.dendrite = MagicMock()\n\ntests/integration/test_miner_validator.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/bittensor/core/synapse.py:503: in __setattr__\n    super().__setattr__(name, value)\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:996: in __setattr__\n    setattr_handler(self, name, value)  # call here to not memo on possibly unknown fields\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = ConversionSynapse(features={'session_id': 'test-session-123', 'conversation_duration_seconds': 120.5, 'has_target_enti...ted_questions': 1, 'message_alternation_rate': 0.91}, prediction=None, confidence=None, response_time=0.0, miner_uid=0)\nname = 'dendrite', val = <MagicMock id='4986020976'>\n\n>       'validate_assignment': lambda model, name, val: model.__pydantic_validator__.validate_assignment(model, name, val),  # pyright: ignore[reportAssignmentType]\n        'private': _private_setattr_handler,\n        'cached_property': lambda model, name, val: model.__dict__.__setitem__(name, val),\n        'extra_known': lambda model, name, val: _object_setattr(model, name, val),\n    }\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for ConversionSynapse\nE   dendrite\nE     Input should be a valid dictionary or instance of TerminalInfo [type=model_type, input_value=<MagicMock id='4986020976'>, input_type=MagicMock]\nE       For further information visit https://errors.pydantic.dev/2.11/v/model_type\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:114: ValidationError"
          },
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_validator_evaluation_of_miner_response",
            "duration": 0.0006880420041852631,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x1291c5c30>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x129203fd0>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_validator_evaluation_of_miner_response(self, mock_miner, sample_features):\n        \"\"\"Test that validator can evaluate miner responses correctly.\"\"\"\n        # Create a sample synapse with features\n        synapse = ConversionSynapse(features=sample_features)\n    \n        # Add required dendrite property for blacklist\n>       synapse.dendrite = MagicMock()\n\ntests/integration/test_miner_validator.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/bittensor/core/synapse.py:503: in __setattr__\n    super().__setattr__(name, value)\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:996: in __setattr__\n    setattr_handler(self, name, value)  # call here to not memo on possibly unknown fields\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmodel = ConversionSynapse(features={'session_id': 'test-session-123', 'conversation_duration_seconds': 120.5, 'has_target_enti...ted_questions': 1, 'message_alternation_rate': 0.91}, prediction=None, confidence=None, response_time=0.0, miner_uid=0)\nname = 'dendrite', val = <MagicMock id='4984939440'>\n\n>       'validate_assignment': lambda model, name, val: model.__pydantic_validator__.validate_assignment(model, name, val),  # pyright: ignore[reportAssignmentType]\n        'private': _private_setattr_handler,\n        'cached_property': lambda model, name, val: model.__dict__.__setitem__(name, val),\n        'extra_known': lambda model, name, val: _object_setattr(model, name, val),\n    }\nE   pydantic_core._pydantic_core.ValidationError: 1 validation error for ConversionSynapse\nE   dendrite\nE     Input should be a valid dictionary or instance of TerminalInfo [type=model_type, input_value=<MagicMock id='4984939440'>, input_type=MagicMock]\nE       For further information visit https://errors.pydantic.dev/2.11/v/model_type\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pydantic/main.py:114: ValidationError"
          },
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_miner_validator_end_to_end",
            "duration": 0.001782499995897524,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x1291c5960>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1292f5750>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_miner_validator_end_to_end(self, mock_miner, sample_features):\n        \"\"\"Test end-to-end flow from validator query to miner to reward calculation.\"\"\"\n        # Create a mock validator with dendrite\n        validator = MagicMock()\n        validator.dendrite = AsyncMock()\n        validator.metagraph = MagicMock()\n        validator.metagraph.axons = [MagicMock()]\n        validator.update_scores = MagicMock()\n        validator.conversation_history = {}\n    \n        # Mock get_random_uids to return [0]\n>       with patch('conversion_subnet.validator.forward.get_random_uids', return_value=[0]):\n\ntests/integration/test_miner_validator.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1447: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12924e8c0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <function forward at 0x10e2848b0> does not have the attribute 'get_random_uids'\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1420: AttributeError"
          },
          {
            "name": "tests/unit/miner/test_miner.py::TestBinaryClassificationMiner::test_forward",
            "duration": 0.0047307909990195185,
            "error_message": "self = <test_miner.TestBinaryClassificationMiner object at 0x1291c7b80>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1293deb30>\nsample_synapse = ConversionSynapse(features={'session_id': 'test-session-123', 'conversation_duration_seconds': 120.5, 'has_target_enti...ted_questions': 1, 'message_alternation_rate': 0.91}, prediction=None, confidence=None, response_time=0.0, miner_uid=0)\n\n    def test_forward(self, mock_miner, sample_synapse):\n        \"\"\"Test the forward method returns the expected output structure.\"\"\"\n        # Mock the model output\n        with patch.object(mock_miner.model, '__call__', return_value=torch.tensor([0.7])):\n            result = mock_miner.forward(sample_synapse)\n    \n            # Check result structure\n            assert 'conversion_happened' in result\n            assert 'time_to_conversion_seconds' in result\n>           assert 'confidence' in result\nE           AssertionError: assert 'confidence' in {'conversion_happened': 0, 'time_to_conversion_seconds': -1.0}\n\ntests/unit/miner/test_miner.py:54: AssertionError"
          },
          {
            "name": "tests/unit/miner/test_miner.py::TestBinaryClassificationMiner::test_forward_negative_case",
            "duration": 0.001012041000649333,
            "error_message": "self = <test_miner.TestBinaryClassificationMiner object at 0x1291c7e50>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1293746a0>\nsample_synapse = ConversionSynapse(features={'session_id': 'test-session-123', 'conversation_duration_seconds': 120.5, 'has_target_enti...ted_questions': 1, 'message_alternation_rate': 0.91}, prediction=None, confidence=None, response_time=0.0, miner_uid=0)\n\n    def test_forward_negative_case(self, mock_miner, sample_synapse):\n        \"\"\"Test the forward method with a negative prediction.\"\"\"\n        # Mock the model output for negative case\n        with patch.object(mock_miner.model, '__call__', return_value=torch.tensor([0.3])):\n            result = mock_miner.forward(sample_synapse)\n    \n            assert result['conversion_happened'] == 0  # 0.3 rounded down\n            assert result['time_to_conversion_seconds'] == -1.0  # Negative for no conversion\n>           assert result['confidence'] == 0.3\nE           KeyError: 'confidence'\n\ntests/unit/miner/test_miner.py:69: KeyError"
          },
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_train_model",
            "duration": 0.037039250004454516,
            "error_message": "self = <test_train.TestModelTraining object at 0x129202500>\nmock_adam = <MagicMock name='Adam' id='4986460464'>\nmock_dataloader = <MagicMock name='DataLoader' id='4986894848'>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1293748b0>\nsample_dataset = (array([[0.02058449, 0.96990985, 0.83244264, 0.21233911, 0.18182497,\n        0.18340451, 0.30424224, 0.52475643, 0.431...3200496 ,\n        0.89552323, 0.38920168, 0.01083765, 0.90538198, 0.09128668]]), array([0, 1, 1, 0, 1, 1, 0, 1, 0, 1]))\n\n    @patch('torch.utils.data.DataLoader')\n    @patch('torch.optim.Adam')\n    def test_train_model(self, mock_adam, mock_dataloader, mock_miner, sample_dataset):\n        \"\"\"Test train_model function.\"\"\"\n        X_train, y_train = sample_dataset\n        X_val, y_val = sample_dataset  # Reuse for validation\n    \n        # Mock DataLoader instances\n        mock_train_loader = MagicMock()\n        mock_val_loader = MagicMock()\n        mock_dataloader.side_effect = [mock_train_loader, mock_val_loader]\n    \n        # Mock optimizer\n        mock_optimizer = MagicMock()\n        mock_adam.return_value = mock_optimizer\n    \n        # Configure mock_train_loader to yield sample data\n        sample_batch = (torch.randn(4, 40), torch.randint(0, 2, (4,)).float())\n        mock_train_loader.__iter__.return_value = [sample_batch]\n        mock_train_loader.__len__.return_value = 1\n    \n        # Configure mock_val_loader to yield sample data\n        mock_val_loader.__iter__.return_value = [sample_batch]\n        mock_val_loader.__len__.return_value = 1\n    \n        # Call train_model\n        history = train_model(\n            miner=mock_miner,\n            X_train=X_train,\n            y_train=y_train,\n            X_val=X_val,\n            y_val=y_val,\n            epochs=1,\n            batch_size=4,\n            learning_rate=0.001,\n            device=\"cpu\"\n        )\n    \n        # Check that optimizer and DataLoader were created correctly\n        mock_adam.assert_called_once()\n        assert mock_dataloader.call_count == 2\n    \n        # Check that the model was put in train mode\n>       mock_miner.model.train.assert_called_once()\nE       AttributeError: 'function' object has no attribute 'assert_called_once'\n\ntests/unit/miner/test_train.py:159: AttributeError"
          },
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_save_model",
            "duration": 0.004306875001930166,
            "error_message": "self = <test_train.TestModelTraining object at 0x129202800>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1294afd30>\ntmp_checkpoint_dir = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-2/test_save_model0/checkpoints')\n\n    def test_save_model(self, mock_miner, tmp_checkpoint_dir):\n        \"\"\"Test save_model function.\"\"\"\n        # Call save_model\n        save_model(mock_miner, tmp_checkpoint_dir, \"test_model.pt\")\n    \n        # Check that the file was created\n        assert (tmp_checkpoint_dir / \"test_model.pt\").exists()\n    \n        # Check that torch.save was called with the correct arguments\n>       mock_miner.model.state_dict.assert_called_once()\nE       AttributeError: 'function' object has no attribute 'assert_called_once'\n\ntests/unit/miner/test_train.py:179: AttributeError"
          },
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_load_model",
            "duration": 0.0034033749980153516,
            "error_message": "self = <test_train.TestModelTraining object at 0x129202b00>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1293bf6a0>\ntmp_checkpoint_dir = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-2/test_load_model0/checkpoints')\n\n    def test_load_model(self, mock_miner, tmp_checkpoint_dir):\n        \"\"\"Test load_model function.\"\"\"\n        # Save a model first\n        save_model(mock_miner, tmp_checkpoint_dir, \"test_model.pt\")\n    \n        # Call load_model\n        load_model(mock_miner, tmp_checkpoint_dir / \"test_model.pt\")\n    \n        # Check that model.load_state_dict was called\n>       mock_miner.model.load_state_dict.assert_called_once()\nE       AttributeError: 'function' object has no attribute 'assert_called_once'\n\ntests/unit/miner/test_train.py:190: AttributeError"
          },
          {
            "name": "tests/unit/validator/test_forward.py::TestForward::test_forward",
            "duration": 0.0009480829976382665,
            "error_message": "self = <Coroutine test_forward>\n\n    def runtest(self) -> None:\n        self.obj = wrap_in_sync(\n            # https://github.com/pytest-dev/pytest-asyncio/issues/596\n            self.obj,  # type: ignore[has-type]\n        )\n>       super().runtest()\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:1069: in inner\n    _loop.run_until_complete(task)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/asyncio/base_events.py:649: in run_until_complete\n    return future.result()\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1393: in patched\n    with self.decoration_helper(patched,\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:135: in __enter__\n    return next(self.gen)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1358: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:492: in enter_context\n    result = _cm_type.__enter__(cm)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1447: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x1293130d0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <function forward at 0x10e2848b0> does not have the attribute 'generate_conversation'\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1420: AttributeError"
          },
          {
            "name": "tests/unit/validator/test_reward.py::TestValidator::test_diversity_reward",
            "duration": 0.0002892499978770502,
            "error_message": "self = <test_reward.TestValidator object at 0x1293088e0>\n\n    def test_diversity_reward(self):\n        \"\"\"Test diversity reward calculation.\"\"\"\n        validator = Validator()\n    \n        # Conservative prediction (0.5) should have 0 diversity reward\n>       assert validator.diversity_reward(0.5) == 0.0\nE       assert 0.5 == 0.0\nE        +  where 0.5 = diversity_reward(0.5)\nE        +    where diversity_reward = <conversion_subnet.validator.reward.Validator object at 0x129228af0>.diversity_reward\n\ntests/unit/validator/test_reward.py:107: AssertionError"
          },
          {
            "name": "tests/unit/validator/test_reward.py::TestValidator::test_reward_full_flow",
            "duration": 0.001134749996708706,
            "error_message": "self = <test_reward.TestValidator object at 0x129308e50>\nmock_log_metrics = <MagicMock name='log_metrics' id='4986888656'>\n\n    @patch('conversion_subnet.validator.utils.log_metrics')\n    def test_reward_full_flow(self, mock_log_metrics):\n        \"\"\"Test the full reward flow for a miner's response.\"\"\"\n        validator = Validator()\n    \n        # Create a sample response\n        response = MagicMock(spec=ConversionSynapse)\n        response.prediction = {'conversion_happened': 1, 'time_to_conversion_seconds': 70.0}\n        response.confidence = 0.8\n        response.response_time = 15.0\n        response.miner_uid = 42\n    \n        # Create sample ground truth\n        true = {'conversion_happened': 1, 'time_to_conversion_seconds': 65.0}\n    \n        # Calculate reward\n        reward = validator.reward(true, response)\n    \n        # Check that reward is calculated correctly\n        assert 0.0 <= reward <= 1.0\n    \n        # Check that EMA is updated\n        assert 42 in validator.ema_scores\n    \n        # Check that ground truth is stored\n        assert true in validator.ground_truth_history\n    \n        # Check that log_metrics is called\n>       mock_log_metrics.assert_called_once_with(response, reward, true)\n\ntests/unit/validator/test_reward.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <MagicMock name='log_metrics' id='4986888656'>\nargs = (<MagicMock spec='ConversionSynapse' id='4986790928'>, 0.5176666666666667, {'conversion_happened': 1, 'time_to_conversion_seconds': 65.0})\nkwargs = {}, msg = \"Expected 'log_metrics' to be called once. Called 0 times.\"\n\n    def assert_called_once_with(self, /, *args, **kwargs):\n        \"\"\"assert that the mock was called exactly once and that that call was\n        with the specified arguments.\"\"\"\n        if not self.call_count == 1:\n            msg = (\"Expected '%s' to be called once. Called %s times.%s\"\n                   % (self._mock_name or 'mock',\n                      self.call_count,\n                      self._calls_repr()))\n>           raise AssertionError(msg)\nE           AssertionError: Expected 'log_metrics' to be called once. Called 0 times.\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:940: AssertionError"
          }
        ]
      }
    }
  ],
  "metadata": {
    "generated_at": "2025-05-03T15:46:59.488058",
    "log_count": 25
  }
}