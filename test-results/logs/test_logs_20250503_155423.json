{
  "logs": [
    {
      "timestamp": "2025-05-03T15:54:21.902491",
      "level": "INFO",
      "message": "Starting test session",
      "metadata": {
        "test_dir": "/Users/admin/Documents/PersonalProjects/bittensor/analytics_framework/test-results"
      }
    },
    {
      "timestamp": "2025-05-03T15:54:21.907320",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:21.910553",
      "level": "ERROR",
      "message": "Error in forward: too many dimensions 'str'",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:21.996054",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:21.998115",
      "level": "ERROR",
      "message": "Error in forward: too many dimensions 'str'",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.006960",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.128705",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.133041",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.137331",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.142304",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.147688",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.149214",
      "level": "ERROR",
      "message": "Error in forward: mat1 and mat2 shapes cannot be multiplied (1x0 and 40x16)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.153821",
      "level": "INFO",
      "message": "Initialized binary classification miner with model: Sequential(\n  (0): Linear(in_features=40, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n  (5): Sigmoid()\n)",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.320649",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-4/test_save_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.323408",
      "level": "INFO",
      "message": "Saved model checkpoint to /private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-4/test_load_model0/checkpoints/test_model.pt",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.508455",
      "level": "ERROR",
      "message": "Missing required features: ['session_id']",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.509760",
      "level": "ERROR",
      "message": "Feature type validation errors: ['has_target_entity must be 0 or 1, got not_an_int']",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.512149",
      "level": "WARNING",
      "message": "Feature hour_of_day could not be converted to float",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:22.713404",
      "level": "INFO",
      "message": "Test session completed",
      "metadata": {}
    },
    {
      "timestamp": "2025-05-03T15:54:23.156346",
      "level": "INFO",
      "message": "Test session finished with exit status 1",
      "metadata": {
        "exitstatus": 1,
        "test_counts": {
          "total": 52,
          "passed": 46,
          "failed": 6,
          "skipped": 0,
          "errors": 0
        },
        "duration": 1.3195199966430664,
        "failed_tests": [
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_miner_response_to_validator",
            "duration": 0.0023347090027527884,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x124119780>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x1241b42e0>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_miner_response_to_validator(self, mock_miner, sample_features):\n        \"\"\"Test that miner can process features and return valid response.\"\"\"\n        # Create a sample synapse with features\n        synapse = ConversionSynapse(features=sample_features)\n    \n        # Create a mock for the dendrite property\n        mock_dendrite = MagicMock()\n        mock_dendrite.hotkey = \"test_hotkey\"\n    \n        # Patch the synapse directly\n        synapse.__dict__['dendrite'] = mock_dendrite\n    \n        # Mock the metagraph for the miner\n        mock_miner.metagraph = MagicMock()\n        mock_miner.metagraph.hotkeys = [\"test_hotkey\"]\n    \n        # Mock the model output - positive prediction (0.8)\n        with patch.object(mock_miner.model, '__call__', return_value=torch.tensor([0.8])):\n            # Process synapse\n>           result = await mock_miner.forward(synapse)\nE           TypeError: object dict can't be used in 'await' expression\n\ntests/integration/test_miner_validator.py:41: TypeError"
          },
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_validator_evaluation_of_miner_response",
            "duration": 0.0018833750000339933,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x124119ab0>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x124237d00>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_validator_evaluation_of_miner_response(self, mock_miner, sample_features):\n        \"\"\"Test that validator can evaluate miner responses correctly.\"\"\"\n        # Create a sample synapse with features\n        synapse = ConversionSynapse(features=sample_features)\n    \n        # Create a mock for the dendrite property\n        mock_dendrite = MagicMock()\n        mock_dendrite.hotkey = \"test_hotkey\"\n    \n        # Patch the synapse directly\n        synapse.__dict__['dendrite'] = mock_dendrite\n    \n        # Mock the metagraph for the miner\n        mock_miner.metagraph = MagicMock()\n        mock_miner.metagraph.hotkeys = [\"test_hotkey\"]\n    \n        # Generate ground truth\n        ground_truth = generate_ground_truth(sample_features)\n    \n        # Mock the model output\n        with patch.object(mock_miner.model, '__call__', return_value=torch.tensor([0.8])):\n            # Process synapse with miner\n>           response = await mock_miner.forward(synapse)\nE           TypeError: object dict can't be used in 'await' expression\n\ntests/integration/test_miner_validator.py:76: TypeError"
          },
          {
            "name": "tests/integration/test_miner_validator.py::TestMinerValidatorIntegration::test_miner_validator_end_to_end",
            "duration": 0.001928915997268632,
            "error_message": "self = <test_miner_validator.TestMinerValidatorIntegration object at 0x1241197e0>\nmock_miner = <conversion_subnet.miner.miner.BinaryClassificationMiner object at 0x12425fdc0>\nsample_features = {'agent_messages_count': 7, 'avg_agent_response_time_seconds': 7.5, 'avg_entity_confidence': 0.87, 'avg_message_length_agent': 55.6, ...}\n\n    async def test_miner_validator_end_to_end(self, mock_miner, sample_features):\n        \"\"\"Test end-to-end flow from validator query to miner to reward calculation.\"\"\"\n        # Create a mock validator with dendrite\n        validator = MagicMock()\n        validator.dendrite = AsyncMock()\n        validator.metagraph = MagicMock()\n        validator.metagraph.axons = [MagicMock()]\n        validator.update_scores = MagicMock()\n        validator.conversation_history = {}\n    \n        # Mock get_random_uids to return [0]\n>       with patch('conversion_subnet.validator.forward.get_random_uids', return_value=[0]):\n\ntests/integration/test_miner_validator.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1447: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x124266b90>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <function forward at 0x121d848b0> does not have the attribute 'get_random_uids'\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1420: AttributeError"
          },
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_train_model",
            "duration": 0.005711958001484163,
            "error_message": "self = <test_train.TestModelTraining object at 0x12415a290>\nmock_adam = <MagicMock name='Adam' id='4901356496'>\nmock_dataloader = <MagicMock name='DataLoader' id='4901262752'>\nsample_dataset = (array([[0.02058449, 0.96990985, 0.83244264, 0.21233911, 0.18182497,\n        0.18340451, 0.30424224, 0.52475643, 0.431...3200496 ,\n        0.89552323, 0.38920168, 0.01083765, 0.90538198, 0.09128668]]), array([0, 1, 1, 0, 1, 1, 0, 1, 0, 1]))\n\n    @patch('torch.utils.data.DataLoader')\n    @patch('torch.optim.Adam')\n    def test_train_model(self, mock_adam, mock_dataloader, sample_dataset):\n        \"\"\"Test train_model function.\"\"\"\n        X_train, y_train = sample_dataset\n        X_val, y_val = sample_dataset  # Reuse for validation\n    \n        # Create mock miner with mock model\n        mock_miner = MagicMock()\n        mock_model = MagicMock()\n        mock_miner.model = mock_model\n    \n        # Mock DataLoader instances\n        mock_train_loader = MagicMock()\n        mock_val_loader = MagicMock()\n        mock_dataloader.side_effect = [mock_train_loader, mock_val_loader]\n    \n        # Mock optimizer\n        mock_optimizer = MagicMock()\n        mock_adam.return_value = mock_optimizer\n    \n        # Configure mock_train_loader to yield sample data\n        sample_batch = (torch.randn(4, 40), torch.randint(0, 2, (4,)).float())\n        mock_train_loader.__iter__.return_value = [sample_batch]\n        mock_train_loader.__len__.return_value = 1\n    \n        # Configure mock_val_loader to yield sample data\n        mock_val_loader.__iter__.return_value = [sample_batch]\n        mock_val_loader.__len__.return_value = 1\n    \n        # Call train_model\n>       history = train_model(\n            miner=mock_miner,\n            X_train=X_train,\n            y_train=y_train,\n            X_val=X_val,\n            y_val=y_val,\n            epochs=1,\n            batch_size=4,\n            learning_rate=0.001,\n            device=\"cpu\"\n        )\n\ntests/unit/miner/test_train.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/train.py:160: in train_model\n    loss = criterion(outputs, labels)\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/nn/modules/module.py:1751: in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: in _call_impl\n    return forward_call(*args, **kwargs)\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/nn/modules/loss.py:699: in forward\n    return F.binary_cross_entropy(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ninput = <MagicMock name='mock.model().squeeze()' id='4901803856'>, target = tensor([1., 1., 0., 1.])\nweight = None, size_average = None, reduce = None, reduction = 'mean'\n\n    def binary_cross_entropy(\n        input: Tensor,\n        target: Tensor,\n        weight: Optional[Tensor] = None,\n        size_average: Optional[bool] = None,\n        reduce: Optional[bool] = None,\n        reduction: str = \"mean\",\n    ) -> Tensor:\n        r\"\"\"Measure Binary Cross Entropy between the target and input probabilities.\n    \n        See :class:`~torch.nn.BCELoss` for details.\n    \n        Args:\n            input: Tensor of arbitrary shape as probabilities.\n            target: Tensor of the same shape as input with values between 0 and 1.\n            weight (Tensor, optional): a manual rescaling weight\n                    if provided it's repeated to match input tensor shape\n            size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n                the losses are averaged over each loss element in the batch. Note that for\n                some losses, there multiple elements per sample. If the field :attr:`size_average`\n                is set to ``False``, the losses are instead summed for each minibatch. Ignored\n                when reduce is ``False``. Default: ``True``\n            reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n                losses are averaged or summed over observations for each minibatch depending\n                on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n                batch element instead and ignores :attr:`size_average`. Default: ``True``\n            reduction (str, optional): Specifies the reduction to apply to the output:\n                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n                ``'mean'``: the sum of the output will be divided by the number of\n                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n                and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n    \n        Examples::\n    \n            >>> input = torch.randn(3, 2, requires_grad=True)\n            >>> target = torch.rand(3, 2, requires_grad=False)\n            >>> loss = F.binary_cross_entropy(torch.sigmoid(input), target)\n            >>> loss.backward()\n        \"\"\"\n        if has_torch_function_variadic(input, target, weight):\n            return handle_torch_function(\n                binary_cross_entropy,\n                (input, target, weight),\n                input,\n                target,\n                weight=weight,\n                size_average=size_average,\n                reduce=reduce,\n                reduction=reduction,\n            )\n        if size_average is not None or reduce is not None:\n            reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)\n        else:\n            reduction_enum = _Reduction.get_enum(reduction)\n        if target.size() != input.size():\n>           raise ValueError(\n                f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}) is deprecated. \"\n                \"Please ensure they have the same size.\"\n            )\nE           ValueError: Using a target size (torch.Size([4])) that is different to the input size (<MagicMock name='mock.model().squeeze().size()' id='4901820048'>) is deprecated. Please ensure they have the same size.\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/nn/functional.py:3560: ValueError"
          },
          {
            "name": "tests/unit/miner/test_train.py::TestModelTraining::test_load_model",
            "duration": 0.0028473329948610626,
            "error_message": "self = <test_train.TestModelTraining object at 0x12415a7a0>\ntmp_checkpoint_dir = PosixPath('/private/var/folders/wg/544yksrd18q2wtz1fyftdm400000gn/T/pytest-of-admin/pytest-4/test_load_model0/checkpoints')\n\n    def test_load_model(self, tmp_checkpoint_dir):\n        \"\"\"Test load_model function.\"\"\"\n        # Create mock miner with mock model\n        mock_miner = MagicMock()\n        mock_model = MagicMock()\n        mock_miner.model = mock_model\n    \n        # Mock state_dict to return a dictionary\n        mock_model.state_dict.return_value = {\"layer1.weight\": torch.randn(5, 5)}\n    \n        # Save a model first\n        save_model(mock_miner, tmp_checkpoint_dir, \"test_model.pt\")\n    \n        # Call load_model\n>       load_model(mock_miner, tmp_checkpoint_dir / \"test_model.pt\")\n\ntests/unit/miner/test_train.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nconversion_subnet/miner/train.py:253: in load_model\n    miner.model.load_state_dict(torch.load(checkpoint_path, map_location=miner.device))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:1516: in load\n    return _load(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2114: in _load\n    result = unpickler.load()\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:532: in load\n    self.append(self.persistent_load(pid))\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2078: in persistent_load\n    typed_storage = load_tensor(\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/serialization.py:2049: in load_tensor\n    typed_storage = torch.storage.TypedStorage(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <[AttributeError(\"'torch.storage.TypedStorage' object has no attribute '_untyped_storage'\") raised in repr()] TypedStorage object at 0x124572140>\ndevice = None, dtype = torch.float32, wrap_storage = <MagicMock name='mock.device()' id='4904663456'>\n_internal = True\n\n    def __init__(\n        self,\n        *args,\n        device=None,\n        dtype=None,\n        wrap_storage=None,\n        _internal=False,\n    ):\n        if not _internal:\n            _warn_typed_storage_removal()\n        arg_error_msg = (\n            \"TypedStorage.__init__ received an invalid combination \"\n            \"of arguments. Expected one of:\\n\"\n            \" * (*, torch.device device, torch.dtype dtype)\\n\"\n            \" * (int size, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (Sequence data, *, torch.device device, torch.dtype dtype)\\n\"\n            \" * (*, UntypedStorage wrap_storage, torch.dtype dtype)\"\n        )\n    \n        if wrap_storage is not None:\n            if len(args) != 0:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nNo positional arguments should be given when using \"\n                    \"'wrap_storage'\"\n                )\n    \n            if dtype is None:\n                raise RuntimeError(\n                    arg_error_msg + \"\\nArgument 'dtype' must be specified\"\n                )\n    \n            if not isinstance(dtype, torch.dtype):\n                raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'dtype' must be torch.dtype, not {type(dtype)}\"\n                )\n    \n            if device is not None:\n                raise RuntimeError(\n                    arg_error_msg\n                    + \"\\nArgument 'device' should not be specified when 'wrap_storage' is given\"\n                )\n    \n            self.dtype = dtype\n    \n            if not isinstance(wrap_storage, torch.UntypedStorage):\n>               raise TypeError(\n                    arg_error_msg\n                    + f\"\\nArgument 'wrap_storage' must be UntypedStorage, but got {type(wrap_storage)}\"\n                )\nE               TypeError: TypedStorage.__init__ received an invalid combination of arguments. Expected one of:\nE                * (*, torch.device device, torch.dtype dtype)\nE                * (int size, *, torch.device device, torch.dtype dtype)\nE                * (Sequence data, *, torch.device device, torch.dtype dtype)\nE                * (*, UntypedStorage wrap_storage, torch.dtype dtype)\nE               Argument 'wrap_storage' must be UntypedStorage, but got <class 'unittest.mock.MagicMock'>\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/torch/storage.py:827: TypeError"
          },
          {
            "name": "tests/unit/validator/test_forward.py::TestForward::test_forward",
            "duration": 0.0006760839969501831,
            "error_message": "self = <Coroutine test_forward>\n\n    def runtest(self) -> None:\n        self.obj = wrap_in_sync(\n            # https://github.com/pytest-dev/pytest-asyncio/issues/596\n            self.obj,  # type: ignore[has-type]\n        )\n>       super().runtest()\n\n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../../../.local/share/virtualenvs/analytics_framework-X_C0rfF4/lib/python3.10/site-packages/pytest_asyncio/plugin.py:1069: in inner\n    _loop.run_until_complete(task)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/asyncio/base_events.py:649: in run_until_complete\n    return future.result()\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1393: in patched\n    with self.decoration_helper(patched,\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:135: in __enter__\n    return next(self.gen)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1358: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/contextlib.py:492: in enter_context\n    result = _cm_type.__enter__(cm)\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1447: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x124180d30>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <function forward at 0x121d848b0> does not have the attribute 'generate_conversation'\n\n../../../../.pyenv/versions/3.10.15/lib/python3.10/unittest/mock.py:1420: AttributeError"
          }
        ]
      }
    }
  ],
  "metadata": {
    "generated_at": "2025-05-03T15:54:23.203421",
    "log_count": 20
  }
}